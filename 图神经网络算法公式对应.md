# 三种常见图神经网络代码与公式对应关系

## 实现GATConv
### 图注意力网络（GAT）的关键公式如下：
```

eij​=LeakyReLU(aT[Whi​∥Whj​])

𝛼𝑖𝑗=softmax𝑗(𝑒𝑖𝑗)=exp⁡(𝑒𝑖𝑗)∑𝑘∈𝑁(𝑖)exp⁡(𝑒𝑖𝑘)

ℎ𝑖′=𝜎(∑𝑗∈𝑁(𝑖)𝛼𝑖𝑗𝑊ℎ𝑗)
```
### 代码实现如下：
#### 基于PyG:
```JavaScript
class PyG_GATConv(MessagePassing):
    def __init__(self, in_channel, out_channel):
        super(PyG_GATConv, self).__init__(aggr='add')
        self.lin = nn.Linear(in_channel, out_channel, bias=False)  # 定义线性变换层 (1)对应公式：h'_i=Wh_i
        self.att = nn.Parameter(torch.Tensor(1, out_channel))  # 定义注意力参数 (2)   对应公式eij​=LeakyReLU(aT[Whi​∥Whj​])
        self.reset_parameters()  # 初始化参数 (3) 

    def reset_parameters(self):
        nn.init.xavier_uniform_(self.lin.weight)  # 初始化线性变换权重 (3)  即W
        nn.init.xavier_uniform_(self.att)  # 初始化注意力权重 (4) 即a

    def forward(self, x, edge_index):
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # 增加自环 (5)
        x = self.lin(x)  # 应用线性变换 (6) hi′=Whi
        alpha = (x @ self.att.t()).squeeze(-1)  # 计算注意力系数 (7)
        ptr = torch.arange(x.size(0) + 1, dtype=torch.long, device=edge_index.device)  # 创建 ptr 索引 (8)
        return self.propagate(edge_index, x=x, alpha=alpha, ptr=ptr)  # 调用 message passing (9)  

    def message(self, x_j, alpha_j, index, ptr, size_i):
        alpha = softmax(alpha_j, index)  # 计算 softmax 注意力系数 (10)
        return x_j * alpha.view(-1, 1)  # 消息传递并加权 (11)

    def update(self, aggr_out):
        return aggr_out  # 更新节点特征 (12)
  ```
#### 基于DGL：
```JavaScript
class DGL_GATConv(nn.Module):
    def __init__(self, in_channel, out_channel):
        super(DGL_GATConv, self).__init__()
        self.in_channel = in_channel
        self.out_channel = out_channel
        self.W = nn.Parameter(torch.Tensor(in_channel, out_channel))  # (2)
        self.att = nn.Parameter(torch.Tensor(1, out_channel))  # (3)
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.xavier_uniform_(self.W)  # 初始化权重矩阵W (2)
        nn.init.xavier_uniform_(self.att)  # 初始化注意力权重向量att (3)

    def forward(self, g, h):
        with g.local_scope():  # 使用局部范围，避免影响原图 (1)
            h = torch.matmul(h, self.W)  # 节点特征的线性变换 (4)
            g.ndata['h'] = h  # 将线性变换后的特征存储在图的节点数据中 (5)
            g.ndata['a'] = torch.matmul(h, self.att.t())  # 计算注意力分数 (6)
            g.apply_edges(fn.u_add_v('a', 'a', 'e'))  # 计算边上的注意力分数 (7)
            e = torch.exp(g.edata.pop('e'))  # 对注意力分数取指数 (8)
            g.edata['a'] = dgl.ops.edge_softmax(g, e)  # 进行softmax归一化 (9)
            g.update_all(fn.u_mul_e('h', 'a', 'm'), fn.sum('m', 'h'))  # 消息传递与聚合 (10)
            return g.ndata.pop('h')  # 返回更新后的节点特征 (11)
```
  ## 实现SAGEConv
### 图注意力网络（GAT）的关键公式如下：
1.  **线性变换节点特征**: 
首先，对节点特征进行线性变换：
    
    

> ℎ𝑖′=𝑊ℎ𝑖

    
    其中，𝑊 是权重矩阵，ℎ𝑖 是节点 𝑖 的特征，ℎ𝑖′​ 是变换后的特征。
    
2.  **聚合邻居节点特征**: 
使用某种聚合函数（如均值、最大值、LSTM等）对节点 𝑖 的邻居节点特征进行聚合：
    

>     ℎ𝑖agg=AGGREGATE𝑗∈𝑁(𝑖)(ℎ𝑗′)

    
    其中，𝑁(𝑖) 表示节点 𝑖 的邻居节点集合，AGGREGATE 是聚合函数，ℎ𝑖agghiagg​ 是聚合后的邻居特征。
    
3.  **结合自身特征和邻居特征**: 将节点 𝑖i 自身的特征和其邻居节点的聚合特征结合在一起，并进行进一步变换：
    
   

>  ℎ𝑖new=𝜎(𝑊combine[ℎ𝑖∥ℎ𝑖agg])

    
    其中，𝑊combine​ 是另一个权重矩阵，∥ 表示特征拼接，𝜎 是激活函数（如ReLU等），ℎ𝑖new 是更新后的特征。
    

### 代码实现如下：

#### 基于PyG：
```JavaScript
class PyG_SAGEConv(MessagePassing):
    def __init__(self, in_channels, out_channels):
        super(PyG_SAGEConv, self).__init__(aggr='mean')  # 定义聚合函数为平均值 (1)
        self.lin = nn.Linear(in_channels, out_channels)  # 定义线性变换层 (2)
        self.update_lin = nn.Linear(in_channels, out_channels)  # 定义更新层 (3)

    def forward(self, x, edge_index):
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # 增加自环 (4)
        x = self.lin(x)  # 应用线性变换 (5)
        return self.propagate(edge_index, x=x)  # 调用消息传递 (6)

    def message(self, x_j):
        return x_j  # 消息传递，直接返回邻居节点的特征 (7)

    def update(self, aggr_out, x):
        combined = torch.cat([x, aggr_out], dim=-1)  # 将中心节点特征与聚合特征拼接 (8)
        return self.update_lin(combined)  # 应用更新层进行特征更新 (9)
  ```
#### 基于DGL：
```JavaScript
class DGL_SAGEConv(nn.Module):
    def __init__(self, in_channel, out_channel):
        super(DGL_SAGEConv, self).__init__()
        self.in_channel = in_channel
        self.out_channel = out_channel
        self.W = nn.Linear(in_channel, out_channel)  # 定义线性变换矩阵W (2)
        self.update_lin = nn.Linear(in_channel + out_channel, out_channel)  # 定义用于更新特征的线性变换矩阵 (8)

    def forward(self, g, h):
        with g.local_scope():  # 在局部范围内操作，防止改变原图结构 (1)
            h_in = h  # 保存输入特征以便之后拼接 (7)
            h = self.W(h)  # 节点特征的线性变换 (2)
            g.ndata['h'] = h  # 将线性变换后的特征存储在图的节点数据中 (3)
            g.update_all(fn.copy_u('h', 'm'), fn.mean('m', 'h'))  # 聚合邻居特征 (4) (5)
            h = g.ndata.pop('h')  # 获取聚合后的特征 (6)
            return self.update_lin(torch.cat([h_in, h], dim=1))  # 拼接输入特征和聚合特征，并进行线性变换 (8)
 ```

