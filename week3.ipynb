{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_LqSe6BOIMO"
   },
   "source": [
    "In this work, you are required to implement an easy linear regression with machine learning methods based on numpy. It is better not to use the deep learning libraries such as PyTorch or Tensorflow .etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOJEgBOHTwG5"
   },
   "source": [
    "The first is the data generation. We can generate data that follows a linear distribution with the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z5aJpqiDNvj8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_data(num):\n",
    "  for _ in range(num):\n",
    "    x = np.random.uniform(-10.0, 10.0)\n",
    "    noise = np.random.normal(0, 1)\n",
    "    y = x * 2 + 1 + noise\n",
    "    yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwsYNcPpVrog"
   },
   "source": [
    "The following is setting the hyperparameters, and the initialization of the learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tpmidqWHV7st"
   },
   "outputs": [],
   "source": [
    "learn_rate = 0.00001\n",
    "epochs = 100\n",
    "display_step = 10\n",
    "np.random.seed(0)\n",
    "w = np.random.rand()\n",
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoLQ2KCMWKz-"
   },
   "source": [
    "So, you only need to write the code to train the learnable parameters w and b. We recommend you use the mean square error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bKv5Se1tWmVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.1081428988039816\n",
      "Epoch 20, Loss: 1.0706186679881302\n",
      "Epoch 30, Loss: 0.9993033964661736\n",
      "Epoch 40, Loss: 1.062585940346843\n",
      "Epoch 50, Loss: 0.9750818101141177\n",
      "Epoch 60, Loss: 1.0057808460372253\n",
      "Epoch 70, Loss: 1.0421114755547025\n",
      "Epoch 80, Loss: 0.9515357446134294\n",
      "Epoch 90, Loss: 1.013298549199908\n",
      "Epoch 100, Loss: 0.9517864270259851\n",
      "Training finished.\n",
      "Learned parameters:\n",
      "w = 1.9973288116307575, b = 0.9683512711624144\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for x0, y0 in get_data(1000):\n",
    "        # 前向传播\n",
    "        y_pred = w * x0 + b\n",
    "        loss = np.mean((y_pred - y0) ** 2)  #采用均方误差\n",
    "\n",
    "        # 后向传播（梯度下降）\n",
    "        dw = np.mean(2 * (y_pred - y0) * x0)\n",
    "        db = np.mean(2 * (y_pred - y0))\n",
    "\n",
    "        # 更新参数\n",
    "        w -= learn_rate * dw\n",
    "        b -= learn_rate * db\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "    # 打印损失\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        avg_loss = total_loss / 1000  # 每个数据点的平均损失\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n",
    "\n",
    "# 打印最终的参数\n",
    "print(\"Training finished.\")\n",
    "print(\"Learned parameters:\")\n",
    "print(f\"w = {w}, b = {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
